{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ce30a7-c6ba-4256-add5-7bc1f4767155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e783f14-1059-45ce-86eb-5ef6e55b996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        config (\"spark.sql.warehouse.dir\",\"/user/hive/warehouse\").\\\n",
    "        enableHiveSupport().\\\n",
    "        appName(\"Spark SQL - Data processing\").\\\n",
    "        master(\"yarn\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acc6c87-a5c7-4993-b478-60b6cd87f153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cca175udemy.asia-south1-c.c.august-key-324503.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark SQL - Data processing</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa2d019c748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dacbf8-33b7-4520-9722-ee8c8b4f8812",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkContext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a2bb1e78e210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SparkContext' is not defined"
     ]
    }
   ],
   "source": [
    "SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a51aa41-8ed6-4d23-8275-c768fe74292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(\"X\", )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf356f5-1113-4df9-92bb-90986bf54d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l).toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4050e319-b47c-436b-9aa5-f82cb4923472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b67c0734-3811-43d4-8676-43ca9b4741a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cd3fb2-ab52-4e62-9ba5-1973d42d7694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+-----+----------+---------+----------+---------+\n",
      "|current_date|year|month|weekofyear|dayofyear|dayofmonth|dayofweek|\n",
      "+------------+----+-----+----------+---------+----------+---------+\n",
      "|  2021-09-09|2021|    9|        36|      252|         9|        5|\n",
      "+------------+----+-----+----------+---------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    current_date().alias('current_date'), \n",
    "    year(current_date()).alias('year'),\n",
    "    month(current_date()).alias('month'),\n",
    "    weekofyear(current_date()).alias('weekofyear'),\n",
    "    dayofyear(current_date()).alias('dayofyear'),\n",
    "    dayofmonth(current_date()).alias('dayofmonth'),\n",
    "    dayofweek(current_date()).alias('dayofweek')\n",
    ").show() #yyyy-MM-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11adc733-0c80-43c9-ba24-1576f081ea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+-----+----------+----+------+------+\n",
      "|current_timestamp      |year|month|dayofmonth|hour|minute|second|\n",
      "+-----------------------+----+-----+----------+----+------+------+\n",
      "|2021-09-09 05:01:32.829|2021|9    |9         |5   |1     |32    |\n",
      "+-----------------------+----+-----+----------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    current_timestamp().alias('current_timestamp'), \n",
    "    year(current_timestamp()).alias('year'),\n",
    "    month(current_timestamp()).alias('month'),\n",
    "    dayofmonth(current_timestamp()).alias('dayofmonth'),\n",
    "    hour(current_timestamp()).alias('hour'),\n",
    "    minute(current_timestamp()).alias('minute'),\n",
    "    second(current_timestamp()).alias('second')\n",
    ").show(truncate=False) #yyyy-MM-dd HH:mm:ss.SSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a657135-a5f0-4d3b-b39e-d08ec699768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = [(20140228, \"28-Feb-2014 10:00:00.123\"),\n",
    "                     (20160229, \"20-Feb-2016 08:08:08.999\"),\n",
    "                     (20171031, \"31-Dec-2017 11:59:59.123\"),\n",
    "                     (20191130, \"31-Aug-2019 00:00:00.000\")\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a423aa55-b757-42d9-92ed-e63633de9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimesDF = spark.createDataFrame(datetimes, schema=\"date BIGINT, time STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a2fe59-867d-4431-8e01-50c16abfde06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+\n",
      "|date    |time                    |\n",
      "+--------+------------------------+\n",
      "|20140228|28-Feb-2014 10:00:00.123|\n",
      "|20160229|20-Feb-2016 08:08:08.999|\n",
      "|20171031|31-Dec-2017 11:59:59.123|\n",
      "|20191130|31-Aug-2019 00:00:00.000|\n",
      "+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcab4eb3-d482-4425-b6c8-49187544b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   to_date|\n",
      "+----------+\n",
      "|2021-03-02|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(to_date(lit('20210302'), 'yyyyMMdd').alias('to_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2fc953f-3e6e-4c59-9900-adfc168cb17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+\n",
      "|date    |time                    |\n",
      "+--------+------------------------+\n",
      "|20140228|28-Feb-2014 10:00:00.123|\n",
      "|20160229|20-Feb-2016 08:08:08.999|\n",
      "|20171031|31-Dec-2017 11:59:59.123|\n",
      "|20191130|31-Aug-2019 00:00:00.000|\n",
      "+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b5a01d4-92c8-4f9f-b284-c53093cc1c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+----------+-----------------------+\n",
      "|date    |time                    |to_date   |to_timestamp           |\n",
      "+--------+------------------------+----------+-----------------------+\n",
      "|20140228|28-Feb-2014 10:00:00.123|2014-02-28|2014-02-28 10:00:00.123|\n",
      "|20160229|20-Feb-2016 08:08:08.999|2016-02-29|2016-02-20 08:08:08.999|\n",
      "|20171031|31-Dec-2017 11:59:59.123|2017-10-31|2017-12-31 11:59:59.123|\n",
      "|20191130|31-Aug-2019 00:00:00.000|2019-11-30|2019-08-31 00:00:00    |\n",
      "+--------+------------------------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn('to_date', to_date(col('date').cast('string'), 'yyyyMMdd')). \\\n",
    "    withColumn('to_timestamp', to_timestamp(col('time'), 'dd-MMM-yyyy HH:mm:ss.SSS')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef9df759-79e8-45a5-ab22-29a372052ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "464aea02-3897-4faa-be0f-d4edc8266c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+-------+------------------------+-----------------------+\n",
      "|date    |time                    |date_ym|time_ym                 |time_ym1               |\n",
      "+--------+------------------------+-------+------------------------+-----------------------+\n",
      "|20140228|28-Feb-2014 10:00:00.123|201402 |28-Feb-2014 10:00:00.123|2014-02-28 10:00:00.123|\n",
      "|20160229|20-Feb-2016 08:08:08.999|201602 |20-Feb-2016 08:08:08.999|2016-02-20 08:08:08.999|\n",
      "|20171031|31-Dec-2017 11:59:59.123|201710 |31-Dec-2017 11:59:59.123|2017-12-31 11:59:59.123|\n",
      "|20191130|31-Aug-2019 00:00:00.000|201911 |31-Aug-2019 00:00:00.000|2019-08-31 00:00:00    |\n",
      "+--------+------------------------+-------+------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF. \\\n",
    "     withColumn( \"date_ym\", date_format(to_date(col(\"date\").cast('string') ,'yyyyMMdd'), 'yyyyMM')). \\\n",
    "     withColumn(\"time_ym\",  col(\"time\").cast('string')). \\\n",
    "     withColumn(\"time_ym1\", to_timestamp(col('time'), 'dd-MMM-yyyy HH:mm:ss.SSS')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f95ba148-9f2c-4624-b768-2f533ee5d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+----------+-----------------------+---------+-------+\n",
      "|date    |time                    |to_date   |to_timestamp           |to_date_1|time_ym|\n",
      "+--------+------------------------+----------+-----------------------+---------+-------+\n",
      "|20140228|28-Feb-2014 10:00:00.123|2014-02-28|2014-02-28 10:00:00.123|null     |null   |\n",
      "|20160229|20-Feb-2016 08:08:08.999|2016-02-29|2016-02-20 08:08:08.999|null     |null   |\n",
      "|20171031|31-Dec-2017 11:59:59.123|2017-10-31|2017-12-31 11:59:59.123|null     |null   |\n",
      "|20191130|31-Aug-2019 00:00:00.000|2019-11-30|2019-08-31 00:00:00    |null     |null   |\n",
      "+--------+------------------------+----------+-----------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF. \\\n",
    "    withColumn('to_date', to_date(col('date').cast('string'), 'yyyyMMdd')). \\\n",
    "    withColumn('to_timestamp', to_timestamp(col('time'), 'dd-MMM-yyyy HH:mm:ss.SSS')). \\\n",
    "    withColumn('to_date_1', to_date(col('time'), 'yyyyMMdd')). \\\n",
    "    withColumn(\"time_ym\", date_format(\"time\", \"yyyyMM\").cast('int')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a60e53-4bc8-4aeb-8c87-13dfa3b67ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
